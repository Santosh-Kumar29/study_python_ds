I’m a Lead Backend Engineer with 3.5 years experience specializing in 
Python, Django, FastAPI, and applied AI systems. 
I’ve built production-grade AI platforms like Chanakya Learning, an OCR-driven exam evaluation 
system, and Chanakya AI, a multilingual RAG platform for education. 
I enjoy building scalable microservices, AI pipelines, and end-to-end systems 
that combine backend engineering with modern LLM capabilities. 
I’m now looking for a role where I can lead architecture decisions, build AI-driven features, 
and contribute to a high-growth startup environment.


- I designed and deployed an end-to-end OCR evaluation pipeline processing thousands of exam sheets asynchronously using Django, Celery, and distributed storage, reducing manual grading effort by 60%.




1. Advanced RAG Architecture Patterns
Chunking strategies
Hybrid retrieval
Re-ranking models
Query rewriting
Handling multilingual input (Hindi + English)




2. Why Basic RAG Fails in Production

User → Embedding → Vector DB → Top 5 Chunks → LLM → Answer


Fails in production because:
Bad chunking
Weak retrieval ranking
Multilingual inconsistency
Hallucination leakage
No fallback strategy
No latency control




1️⃣ RAG + Tool Agent
Flow:
User asks question
Retrieve documents
LLM analyzes
If missing data → call search tool
Validate answer
Return result


2️⃣ Multi-Agent System
Example:
Research agent
Summarizer agent
Validator agent


3. What problem does LangGraph solve?

LangGraph provides explicit stateful control over LLM-based workflows by modeling them as directed graphs. It enables conditional branching, looping, memory persistence, and multi-agent coordination, which are difficult to implement cleanly using standard chain-based abstractions.


